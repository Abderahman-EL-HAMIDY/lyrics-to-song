{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/suno-ai/bark.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-21T16:57:01.998952Z","iopub.execute_input":"2025-12-21T16:57:01.999135Z","iopub.status.idle":"2025-12-21T16:57:18.335249Z","shell.execute_reply.started":"2025-12-21T16:57:01.999116Z","shell.execute_reply":"2025-12-21T16:57:18.334342Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/suno-ai/bark.git\n  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-9unawq_z\n  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-9unawq_z\n  Resolved https://github.com/suno-ai/bark.git to commit f4f32d4cd480dfec1c245d258174bc9bde3c2148\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (1.42.10)\nCollecting encodec (from suno-bark==0.0.1a0)\n  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: funcy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.0)\nRequirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (0.36.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.0.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (1.15.3)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (0.22.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.8.0+cu126)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (4.67.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (4.57.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (1.2.1rc0)\nRequirement already satisfied: botocore<1.43.0,>=1.42.10 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (1.42.10)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (1.0.1)\nRequirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (0.16.0)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from encodec->suno-bark==0.0.1a0) (2.8.0+cu126)\nRequirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from encodec->suno-bark==0.0.1a0) (0.8.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->suno-bark==0.0.1a0) (2025.11.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->suno-bark==0.0.1a0) (0.6.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (2.9.0.post0)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (2.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->suno-bark==0.0.1a0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.11)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2025.11.12)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (1.17.0)\nBuilding wheels for collected packages: suno-bark, encodec\n  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567394 sha256=dcd576461581c8933f2b1a6d05aa3d1aa80a280fc20fdceedc17449537f3fa32\n  Stored in directory: /tmp/pip-ephem-wheel-cache-b5p3yccz/wheels/1d/f3/b7/b089fb43ad6f66ce7cb3185bb697a3fc547067ac7fe9ad4947\n  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=9acfe53fe00b496830cc77bbdc325f529cf6c59c4644e5c8291287b4974fde11\n  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\nSuccessfully built suno-bark encodec\nInstalling collected packages: encodec, suno-bark\nSuccessfully installed encodec-0.1.1 suno-bark-0.0.1a0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import AutoProcessor, MusicgenForConditionalGeneration, BarkModel\nfrom transformers import AutoProcessor as BarkProcessor\nimport torch\nimport scipy.io.wavfile as wavfile\nimport numpy as np\nimport librosa\nimport tempfile\nimport gc\n\n# ==========================================\n#   HELPER: VRAM CLEANER\n# ==========================================\ndef flush():\n    \"\"\"Forces the GPU to release memory between steps\"\"\"\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# ==========================================\n#   STEP 1: GENERATE VOCALS (BARK)\n# ==========================================\ndef step_1_vocals(lyrics_text):\n    print(\"--- [1/3] Starting Vocals Generation ---\")\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # Load Bark (Small version is safer for VRAM)\n    processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n    model = BarkModel.from_pretrained(\"suno/bark-small\").to(device)\n    \n    # Add music notes to prompt to trigger singing mode\n    formatted_prompt = f\"♪ {lyrics_text} ♪\"\n    \n    inputs = processor(formatted_prompt, voice_preset=\"v2/en_speaker_6\").to(device)\n    \n    # Generate\n    audio_array = model.generate(**inputs)\n    audio_array = audio_array.cpu().numpy().squeeze()\n    \n    # Get sample rate before deleting model\n    sr = model.generation_config.sample_rate\n    \n    # Cleanup\n    del model\n    del processor\n    del inputs\n    flush()\n    \n    return audio_array, sr\n\n# ==========================================\n#   STEP 2: GENERATE MUSIC (MUSICGEN SMALL)\n# ==========================================\ndef step_2_music(style_text):\n    print(\"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\")\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # CHANGED: Using 'musicgen-small' and the standard ConditionalGeneration class\n    processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n    model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\").to(device)\n    \n    # CHANGED: We no longer pass 'audio' here. Just text.\n    inputs = processor(\n        text=[style_text],\n        padding=True,\n        return_tensors=\"pt\",\n    ).to(device)\n    \n    # Generate\n    audio_values = model.generate(\n        **inputs,\n        do_sample=True,\n        guidance_scale=3,\n        max_new_tokens=512 # Approx 5 seconds (Increase to 512 or 768 for longer audio)\n    )\n    \n    music_array = audio_values[0].cpu().numpy().squeeze()\n    \n    # Cleanup\n    del model\n    del processor\n    del inputs\n    flush()\n    \n    return music_array, 32000\n\n# ==========================================\n#   STEP 3: MIXER & MAIN PIPELINE\n# ==========================================\ndef full_song_pipeline(lyrics, style, progress=gr.Progress()):\n    try:\n        progress(0.1, desc=\"Warming up the singer (Bark)...\")\n        \n        # 1. Generate Vocals\n        vocab_raw, vocab_sr = step_1_vocals(lyrics)\n        \n        progress(0.4, desc=\"The band is playing (MusicGen Small)...\")\n        \n        # 2. Generate Music \n        # CHANGED: Removed vocal inputs here. Music is generated independently.\n        music_raw, music_sr = step_2_music(style)\n        \n        progress(0.8, desc=\"Mixing final track...\")\n        \n        # 3. Mixing (The crucial step!)\n        # We need both arrays to be the same length and sample rate (32k)\n        \n        # Ensure Vocals are 32k for mixing\n        if vocab_sr != 32000:\n            vocab_final = librosa.resample(vocab_raw, orig_sr=vocab_sr, target_sr=32000)\n        else:\n            vocab_final = vocab_raw\n\n        # Pad the shorter audio with zeros so they can be added\n        max_len = max(len(vocab_final), len(music_raw))\n        \n        # Pad Vocals\n        vocab_padded = np.pad(vocab_final, (0, max_len - len(vocab_final)))\n        # Pad Music\n        music_padded = np.pad(music_raw, (0, max_len - len(music_raw)))\n        \n        # Normalize volumes before mixing\n        # Check for zeros to avoid divide by zero errors\n        if np.abs(vocab_padded).max() > 0:\n            vocab_padded = vocab_padded / np.abs(vocab_padded).max()\n        if np.abs(music_padded).max() > 0:\n            music_padded = music_padded / np.abs(music_padded).max()\n        \n        # Mix: 60% Vocals, 40% Music (Adjust to taste)\n        mixed_audio = (vocab_padded * 0.6) + (music_padded * 0.4)\n        \n        # Convert to Int16 for WAV file\n        mixed_audio = (mixed_audio * 32767).astype(np.int16)\n        \n        # Save\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n            wavfile.write(tmp_file.name, 32000, mixed_audio)\n            return tmp_file.name\n            \n    except Exception as e:\n        # If error, print it to the UI\n        raise gr.Error(f\"Pipeline crashed: {str(e)}\")\n\n# ==========================================\n#   GRADIO INTERFACE\n# ==========================================\ncss = \"\"\"\n.container {max-width: 800px; margin: auto; padding-top: 20px}\n\"\"\"\n\nwith gr.Blocks(css=css, title=\"One-Click Music Generator\") as demo:\n    gr.Markdown(\"# AI Song Maker (Small Model)\")\n    gr.Markdown(\"Enter lyrics and style. Note: Music is now generated independently of the vocal melody.\")\n    \n    with gr.Group():\n        lyrics_input = gr.Textbox(\n            label=\"Lyrics\", \n            placeholder=\"Type your song lyrics here...\", \n            lines=3,\n            value=\"Neon lights in the city rain, washing away all my pain.\"\n        )\n        \n        style_input = gr.Textbox(\n            label=\"Music Style\", \n            placeholder=\"E.g., Jazz, Rock, Synthwave...\", \n            value=\"Synthwave 80s pop with heavy drums\"\n        )\n        \n        generate_btn = gr.Button(\"Generate Full Song\", variant=\"primary\", size=\"lg\")\n    \n    output_audio = gr.Audio(label=\"Your Generated Song\", type=\"filepath\")\n    \n    # Trigger\n    generate_btn.click(\n        fn=full_song_pipeline,\n        inputs=[lyrics_input, style_input],\n        outputs=[output_audio]\n    )\n\nprint(\"Launching App...\")\ndemo.launch(share=True, debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T17:39:55.201621Z","iopub.execute_input":"2025-12-21T17:39:55.202170Z"}},"outputs":[{"name":"stderr","text":"2025-12-21 17:40:13.304858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766338813.469940      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766338813.510554      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766338813.856615      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766338813.856649      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766338813.856652      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766338813.856654      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Launching App...\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://75c1b211d00377fb18.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://75c1b211d00377fb18.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stdout","text":"--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d3e5e5b41c4220a34ce50fc2f4c6ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"speaker_embeddings_path.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b6547733c043809b99d9aeb5345748"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4971fe3400c7444d92b8e6f68d05829a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d784e69f5a8f4f98b3fa576010b08836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d622ec65fcbc4c3db4315a875af64b5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65faaa747e6404cb0486b7a7c43fd1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e0bd05a65904d20b2fc8139dc600ea0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199d4177e57e4ab78bafe5494bfd7298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b48a2be7b904693aa2f4f241a4eac38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"speaker_embeddings/v2/en_speaker_6_seman(…):   0%|          | 0.00/2.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6e18266072427e8aeb893242835732"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"speaker_embeddings/v2/en_speaker_6_coars(…):   0%|          | 0.00/7.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ec171406944679bab8c5a24d387d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"speaker_embeddings/v2/en_speaker_6_fine_(…):   0%|          | 0.00/15.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3c764a8e7694568898b1ddfbb02b73b"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18a010d01e74422ab4f94634c2cfab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45e5739dbcb4b30b2d3cc7fd71e50b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c8f4c0d3204dc1bc7997ef8c64f5d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e64992d6d0a4016b06de9482997edf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a7e82c7afe489bb7bc1ac48195ea97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bacccb20c88e44ab9cdf9233599a33cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e7609074e349f8b810ca3c65da309f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63983de208f6456d9b19a15817f05c68"}},"metadata":{}},{"name":"stdout","text":"--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n--- [1/3] Starting Vocals Generation ---\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}