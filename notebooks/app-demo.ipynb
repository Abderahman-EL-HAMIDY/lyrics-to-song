{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-21T16:57:01.999135Z",
     "iopub.status.busy": "2025-12-21T16:57:01.998952Z",
     "iopub.status.idle": "2025-12-21T16:57:18.335249Z",
     "shell.execute_reply": "2025-12-21T16:57:18.334342Z",
     "shell.execute_reply.started": "2025-12-21T16:57:01.999116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/suno-ai/bark.git\n",
      "  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-9unawq_z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-9unawq_z\n",
      "  Resolved https://github.com/suno-ai/bark.git to commit f4f32d4cd480dfec1c245d258174bc9bde3c2148\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (1.42.10)\n",
      "Collecting encodec (from suno-bark==0.0.1a0)\n",
      "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (0.36.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (1.15.3)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (0.22.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (4.67.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from suno-bark==0.0.1a0) (4.57.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (1.2.1rc0)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.10 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (1.42.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3->suno-bark==0.0.1a0) (0.16.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from encodec->suno-bark==0.0.1a0) (2.8.0+cu126)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from encodec->suno-bark==0.0.1a0) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->suno-bark==0.0.1a0) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->suno-bark==0.0.1a0) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->suno-bark==0.0.1a0) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (2.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->suno-bark==0.0.1a0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2025.11.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.10->boto3->suno-bark==0.0.1a0) (1.17.0)\n",
      "Building wheels for collected packages: suno-bark, encodec\n",
      "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567394 sha256=dcd576461581c8933f2b1a6d05aa3d1aa80a280fc20fdceedc17449537f3fa32\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b5p3yccz/wheels/1d/f3/b7/b089fb43ad6f66ce7cb3185bb697a3fc547067ac7fe9ad4947\n",
      "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=9acfe53fe00b496830cc77bbdc325f529cf6c59c4644e5c8291287b4974fde11\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
      "Successfully built suno-bark encodec\n",
      "Installing collected packages: encodec, suno-bark\n",
      "Successfully installed encodec-0.1.1 suno-bark-0.0.1a0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/suno-ai/bark.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T17:39:55.202170Z",
     "iopub.status.busy": "2025-12-21T17:39:55.201621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 17:40:13.304858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766338813.469940      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766338813.510554      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766338813.856615      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766338813.856649      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766338813.856652      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766338813.856654      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching App...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://75c1b211d00377fb18.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://75c1b211d00377fb18.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d3e5e5b41c4220a34ce50fc2f4c6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b6547733c043809b99d9aeb5345748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "speaker_embeddings_path.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4971fe3400c7444d92b8e6f68d05829a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d784e69f5a8f4f98b3fa576010b08836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d622ec65fcbc4c3db4315a875af64b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65faaa747e6404cb0486b7a7c43fd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0bd05a65904d20b2fc8139dc600ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199d4177e57e4ab78bafe5494bfd7298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b48a2be7b904693aa2f4f241a4eac38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6e18266072427e8aeb893242835732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "speaker_embeddings/v2/en_speaker_6_seman(…):   0%|          | 0.00/2.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec171406944679bab8c5a24d387d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "speaker_embeddings/v2/en_speaker_6_coars(…):   0%|          | 0.00/7.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c764a8e7694568898b1ddfbb02b73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "speaker_embeddings/v2/en_speaker_6_fine_(…):   0%|          | 0.00/15.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18a010d01e74422ab4f94634c2cfab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45e5739dbcb4b30b2d3cc7fd71e50b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c8f4c0d3204dc1bc7997ef8c64f5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64992d6d0a4016b06de9482997edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a7e82c7afe489bb7bc1ac48195ea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacccb20c88e44ab9cdf9233599a33cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e7609074e349f8b810ca3c65da309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63983de208f6456d9b19a15817f05c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n",
      "--- [1/3] Starting Vocals Generation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [2/3] Starting Music Generation (No Audio Conditioning) ---\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration, BarkModel\n",
    "from transformers import AutoProcessor as BarkProcessor\n",
    "import torch\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tempfile\n",
    "import gc\n",
    "\n",
    "# ==========================================\n",
    "#   HELPER: VRAM CLEANER\n",
    "# ==========================================\n",
    "def flush():\n",
    "    \"\"\"Forces the GPU to release memory between steps\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ==========================================\n",
    "#   STEP 1: GENERATE VOCALS (BARK)\n",
    "# ==========================================\n",
    "def step_1_vocals(lyrics_text, voice_preset):\n",
    "    print(f\"--- [1/3] Starting Vocals Generation (Voice: {voice_preset}) ---\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load Bark (Small version is safer for VRAM)\n",
    "    processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n",
    "    model = BarkModel.from_pretrained(\"suno/bark-small\").to(device)\n",
    "    \n",
    "    # Add music notes to prompt to trigger singing mode\n",
    "    formatted_prompt = f\"♪ {lyrics_text} ♪\"\n",
    "    \n",
    "    # CHANGED: Now using the voice_preset variable passed from the button\n",
    "    inputs = processor(formatted_prompt, voice_preset=voice_preset).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    audio_array = model.generate(**inputs)\n",
    "    audio_array = audio_array.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get sample rate before deleting model\n",
    "    sr = model.generation_config.sample_rate\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    del processor\n",
    "    del inputs\n",
    "    flush()\n",
    "    \n",
    "    return audio_array, sr\n",
    "\n",
    "# ==========================================\n",
    "#   STEP 2: GENERATE MUSIC (MUSICGEN SMALL)\n",
    "# ==========================================\n",
    "def step_2_music(style_text):\n",
    "    print(\"--- [2/3] Starting Music Generation (No Audio Conditioning) ---\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Using 'musicgen-small'\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "    model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\").to(device)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[style_text],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    audio_values = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        guidance_scale=3,\n",
    "        max_new_tokens=768 \n",
    "    )\n",
    "    \n",
    "    music_array = audio_values[0].cpu().numpy().squeeze()\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    del processor\n",
    "    del inputs\n",
    "    flush()\n",
    "    \n",
    "    return music_array, 32000\n",
    "\n",
    "# ==========================================\n",
    "#   STEP 3: MIXER & MAIN PIPELINE\n",
    "# ==========================================\n",
    "def full_song_pipeline(lyrics, style, voice_choice, progress=gr.Progress()):\n",
    "    try:\n",
    "        # MAP BUTTON CHOICE TO BARK PRESET ID\n",
    "        if voice_choice == \"Female\":\n",
    "            selected_voice = \"v2/en_speaker_9\"\n",
    "        else:\n",
    "            selected_voice = \"v2/en_speaker_6\" # Default Male\n",
    "\n",
    "        progress(0.1, desc=\"Warming up the singer (Bark)...\")\n",
    "        \n",
    "        # 1. Generate Vocals (Pass the selected voice)\n",
    "        vocab_raw, vocab_sr = step_1_vocals(lyrics, selected_voice)\n",
    "        \n",
    "        progress(0.4, desc=\"The band is playing (MusicGen Small)...\")\n",
    "        \n",
    "        # 2. Generate Music \n",
    "        music_raw, music_sr = step_2_music(style)\n",
    "        \n",
    "        progress(0.8, desc=\"Mixing final track...\")\n",
    "        \n",
    "        # 3. Mixing\n",
    "        if vocab_sr != 32000:\n",
    "            vocab_final = librosa.resample(vocab_raw, orig_sr=vocab_sr, target_sr=32000)\n",
    "        else:\n",
    "            vocab_final = vocab_raw\n",
    "\n",
    "        max_len = max(len(vocab_final), len(music_raw))\n",
    "        \n",
    "        vocab_padded = np.pad(vocab_final, (0, max_len - len(vocab_final)))\n",
    "        music_padded = np.pad(music_raw, (0, max_len - len(music_raw)))\n",
    "        \n",
    "        if np.abs(vocab_padded).max() > 0:\n",
    "            vocab_padded = vocab_padded / np.abs(vocab_padded).max()\n",
    "        if np.abs(music_padded).max() > 0:\n",
    "            music_padded = music_padded / np.abs(music_padded).max()\n",
    "        \n",
    "        mixed_audio = (vocab_padded * 0.6) + (music_padded * 0.4)\n",
    "        \n",
    "        mixed_audio = (mixed_audio * 32767).astype(np.int16)\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
    "            wavfile.write(tmp_file.name, 32000, mixed_audio)\n",
    "            return tmp_file.name\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Pipeline crashed: {str(e)}\")\n",
    "\n",
    "# ==========================================\n",
    "#   GRADIO INTERFACE\n",
    "# ==========================================\n",
    "css = \"\"\"\n",
    ".container {max-width: 800px; margin: auto; padding-top: 20px}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css, title=\"One-Click Music Generator\") as demo:\n",
    "    gr.Markdown(\"# AI Song Maker\")\n",
    "    gr.Markdown(\"Enter lyrics and style.\")\n",
    "    \n",
    "    with gr.Group():\n",
    "        # NEW: Voice Selection Button\n",
    "        voice_btn = gr.Radio(\n",
    "            choices=[\"Male\", \"Female\"], \n",
    "            value=\"Male\", \n",
    "            label=\"Singer Voice\",\n",
    "            interactive=True\n",
    "        )\n",
    "\n",
    "        lyrics_input = gr.Textbox(\n",
    "            label=\"Lyrics\", \n",
    "            placeholder=\"Type your song lyrics here...\", \n",
    "            lines=3,\n",
    "            value=\"I’m focused.\\nLocked in.\\nNo breaks, NO SLEEP.\\nno fear.\\nNo Fear.\\nI stay on time.\"\n",
    "        )\n",
    "        \n",
    "        style_input = gr.Textbox(\n",
    "            label=\"Music Style\", \n",
    "            placeholder=\"E.g., Jazz, Rock, Synthwave...\", \n",
    "            value=\"Modern motivational rap track, medium-fast tempo around 100 BPM, confident and determined mood.\"\n",
    "        )\n",
    "        \n",
    "        generate_btn = gr.Button(\"Generate Full Song\", variant=\"primary\", size=\"lg\")\n",
    "    \n",
    "    output_audio = gr.Audio(label=\"Your Generated Song\", type=\"filepath\")\n",
    "    \n",
    "    # Trigger\n",
    "    generate_btn.click(\n",
    "        fn=full_song_pipeline,\n",
    "        inputs=[lyrics_input, style_input, voice_btn], # Added voice_btn here\n",
    "        outputs=[output_audio]\n",
    "    )\n",
    "\n",
    "print(\"Launching App...\")\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
